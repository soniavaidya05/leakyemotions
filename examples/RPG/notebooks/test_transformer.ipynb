{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer model + RPG testing pipeline\n",
    "\n",
    "This document lays out the procedure for:\n",
    "- Training the forward model to learn the RPG environment and saving it to disk\n",
    "- Using the trained forward model to generate expert memories and saving them\n",
    "- Loading the expert memories into the transformer model\n",
    "- Training the transformer model\n",
    "\n",
    "## Table of Contents\n",
    "1. [Train the forward model](#Train-the-forward-model)\n",
    "2. [Locate the saved model](#Locate-the-saved-model)\n",
    "3. [Generate memories and save to disk](#Generate-memories-and-save-to-disk)\n",
    "4. [Evaluate the transformer model](#Evaluate-the-transformer-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------- #\n",
    "# region: Imports #\n",
    "# --------------- #\n",
    "\n",
    "# Import base packages\n",
    "import os\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "# region: Fix path nonsense\n",
    "module_path = os.path.abspath('../../..')\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)\n",
    "# endregion\n",
    "\n",
    "# --------------- #\n",
    "# endregion       #\n",
    "# --------------- #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the forward model\n",
    "\n",
    "To give the transformer model something to learn, we need to first train a model to solve the RPG task.\n",
    "\n",
    "To edit details of the model training regime, use the configuration file (by default, stored in `../configs/config.yaml` relative to this Python notebook) to change them. Some details need to be changed together for the model to successfully run.\n",
    "\n",
    "In addition to providing a simple console log summary of each epoch, more detailed data is stored in TensorBoard if `log` in the configuration file is set to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from examples.RPG.main import run, load_config\n",
    "\n",
    "# Specify configuration path\n",
    "config_path = '../configs/config.yaml'\n",
    "# Load configuration\n",
    "cfg = load_config(argparse.Namespace(config=config_path))\n",
    "# Specify the model path to save your model to (cfg.root specifies the root module directory in the configuration file)\n",
    "model_path = f'{cfg.root}/examples/RPG/models/checkpoints/iRainbowModel_{datetime.now().strftime(\"%Y%m%d-%H%m%s\")}.pkl'\n",
    "\n",
    "# Run the model. The model has a **kwargs parameter that allows you to specify two model conditions:\n",
    "#   - load_weights allows you to specify a file path start the model with pretrained model weights\n",
    "#   - save weights allows you to specify a file path to save your model weights to. \n",
    "#     NOTE: The model directory must already exist, or the save function will fail!\n",
    "\n",
    "# Run the forward model with the specified configuration\n",
    "run(cfg, save_weights=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locate the saved model\n",
    "\n",
    "Once a trained model is saved to disk, using it again is just a matter of creating a new python object with the same configurations.\n",
    "\n",
    "```py\n",
    "model_path = '/path/to/model.pkl'\n",
    "\n",
    "model = iRainbowModel(\n",
    "    ...# pass in parameters\n",
    ")\n",
    "\n",
    "model.load(model_path) # Now the model is ready to use again.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate memories and save to disk\n",
    "\n",
    "Generating memories of game trajectories, replays of games, and model scores on games is achieved using the `eval_model()` function. This function plays a specified number of games (by default, 1) and returns a dictionary of output variables. The memories file is somewhat large (~ 1.5 GB for 1024 games), so keep that in mind.\n",
    "\n",
    "Flags that can be used:\n",
    "- `'memories'` returns a stored memory buffer of size (n_games x max_turns)\n",
    "- `'frames'` returns a list of size (n_games x max_turns) with images of each turn.\n",
    "- `'scores` returns a record of the model's reward on each turn.\n",
    "- `'jupyter-mode'` should be added when you are using `'frames'` from a Python notebook rather than from the command line.\n",
    "\n",
    "**NOTE**: As generating the frames takes a while, it's generally faster to generate animated replays and memories separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.RPG.test import eval_model\n",
    "from agentarium.utils.visualization import animate\n",
    "\n",
    "results = eval_model(\n",
    "    'memories',\n",
    "    model_path=model_path,\n",
    "    config_path=config_path,\n",
    "    n_games=1024\n",
    ")\n",
    "\n",
    "# Save the stored memories\n",
    "memories = results['memories']\n",
    "memories_path = '../data/memories.pkl'\n",
    "memories.save(file_path=memories_path)\n",
    "\n",
    "# # Replay one game\n",
    "# results = eval_model(\n",
    "#     'frames', 'jupyter-mode'\n",
    "#     model_path=model_path,\n",
    "#     config_path=config_path,\n",
    "#     n_games=1\n",
    "# )\n",
    "\n",
    "# data_folder = '../data/'\n",
    "# game = results['frames'][0]\n",
    "# animate(\n",
    "#     game,\n",
    "#     filename='model_test',\n",
    "#     folder=data_folder\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the transformer model\n",
    "\n",
    "The transformer model uses a separate configuration file (by default, `../configs/transformer.yaml`). This file is shorter and handles only the details of the transformer model itself, since all of the details of the environment were already established when training the forward model. Make sure that the input parameters are compatible with those used by the forward model.\n",
    "\n",
    "**NOTE**: Be aware that at this stage, some specific configurations are not compatible with the transformer model. For example, the transformer model requires the state space to be evenly divisible by a patch size. Since the agent vision results in an odd-numbered state H x W, the state size in the forward model must have a H x W of e.g., 9 x 9, 15 x 15, 21 x 21 in order to have a patch size of 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.RPG.test import train_transformer_model\n",
    "\n",
    "# Load configuration path\n",
    "transformer_config_path = '../configs/transformer.yaml'\n",
    "cfg = load_config(argparse.Namespace(config=transformer_config_path))\n",
    "\n",
    "# Train the transformer model\n",
    "train_transformer_model(cfg, memories_path=memories_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
